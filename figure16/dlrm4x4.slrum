#!/bin/bash

#SBATCH --account={your_account}
#SBATCH --partition={your_partition}

#SBATCH --nodes=4
#SBATCH --gpus-per-node=4
#SBATCH --ntasks-per-node=4
#SBATCH --cpus-per-task=4

#SBATCH -o figure16/slogs/dlrm4x4-%j.out

run_script=${1:-"figure16/e2e.py"}
local_batch_size=${2:-"8192"}
results_file=${5:-"figure16/results.txt"}


sp_dir="datasets/dlrm_pt/2022/splits"

if [ ! -d "figure16/slogs" ]; then
    mkdir -p "figure16/slogs"
fi

# Batch-wise pipeline
echo "Batch-wise Pipeline" > ${results_file}
for num_global_keys in 788 480 240
do
    echo "Dataset: Meta-${num_global_keys}: " >> ${results_file}

    srun python ${run_script} --launch=slurm \
        --local_batch_size=${local_batch_size} --skew_degree=1 \
        --parallel=bwp --model=EcoRec --num_micro_uidx=4 --reordering \
        --sp_dir=${sp_dir} --num_micro_batches=4 --sharding_method=greed \
        --num_global_keys=${num_global_keys} --log_file="temp.txt"

    cat temp.txt >> ${results_file}
done

# Table-wise pipeline
echo "==================================" >> ${results_file}
echo "Table-wise pipeline benchmark" >> ${results_file}
for num_global_keys in 788 480 240
do
    echo "Dataset: Meta-${num_global_keys}: " >> ${results_file}

    srun python ${run_script} --launch=slurm \
        --local_batch_size=${local_batch_size} \
        --parallel=twp --model=EcoRec --num_micro_uidx=4 \
        --sp_dir=${sp_dir} --num_micro_batches=4 --sharding_method=greed \
        --num_global_keys=${num_global_keys} --log_file="temp.txt"

    cat temp.txt >> ${results_file}
done

# Table-wise pipeline + Reordering
echo "==================================" >> ${results_file}
echo "Table-wise pipeline + Reordering benchmark" >> ${results_file}
for num_global_keys in 788 480 240
do
    echo "Dataset: Meta-${num_global_keys}: " >> ${results_file}

    srun python ${run_script} --launch=slurm \
        --local_batch_size=${local_batch_size} \
        --parallel=twp --model=EcoRec --num_micro_uidx=4 --reordering \
        --sp_dir=${sp_dir} --num_micro_batches=4 --sharding_method=greed \
        --num_global_keys=${num_global_keys} --log_file="temp.txt"

    cat temp.txt >> ${results_file}
done


# Table-wise pipeline + Reordering + Slope features
echo "==================================" >> ${results_file}
echo "Table-wise pipeline + Reordering + Slope features benchmark" >> ${results_file}
for num_global_keys in 788 480 240
do
    echo "Dataset: Meta-${num_global_keys}: " >> ${results_file}

    srun python ${run_script} --launch=slurm \
        --local_batch_size=${local_batch_size} --skew_degree=1 \
        --parallel=twp --model=EcoRec --num_micro_uidx=4 --reordering \
        --sp_dir=${sp_dir} --num_micro_batches=4 --sharding_method=greed \
        --num_global_keys=${num_global_keys} --log_file="temp.txt"

    cat temp.txt >> ${results_file}
done